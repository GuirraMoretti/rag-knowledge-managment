{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc8740a",
   "metadata": {},
   "source": [
    "# Uso de RAG para recuperar conhecimento organizacional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277da8e0",
   "metadata": {},
   "source": [
    "## Objetivo: Criar uma rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain-community langchain-text-splitters dotenv langchain-google-genai chromadb pypdf langchain-mistralai ipywidgets unstructured langchain-google-vertexai pdfminer.six sentence_transformers langchain-huggingface unstructured[local-inference]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b19aa",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc8cd28",
   "metadata": {},
   "source": [
    "### Bibliotecas suporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b97c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict, List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad627b",
   "metadata": {},
   "source": [
    "### Parser e chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4cf2970",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bfe179",
   "metadata": {},
   "source": [
    "### LLM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "494ff760",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groq\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#Gemini\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f5ba29",
   "metadata": {},
   "source": [
    "### Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "537e1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gemini\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "# HuggingFace\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "#MistralAI\n",
    "from langchain_mistralai import MistralAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ba57d",
   "metadata": {},
   "source": [
    "### Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15fc48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20b93bb",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9708d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ec2299",
   "metadata": {},
   "source": [
    "## Codigo da RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995c023",
   "metadata": {},
   "source": [
    "### Configurar chaves das API's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61acfb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")\n",
    "_set_env(\"GOOGLE_API_KEY\")\n",
    "\n",
    "folder = \"/home/gui/rag-knowledge-managment/docs/pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff51eef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_documentos(pasta):\n",
    "    docs = []\n",
    "    for arquivo in os.listdir(pasta):\n",
    "        if arquivo.lower().endswith('.pdf'):\n",
    "            caminho = os.path.join(pasta, arquivo)\n",
    "            docs.extend(UnstructuredPDFLoader(caminho).load())\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b44b6ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings():\n",
    "    return MistralAIEmbeddings(model=\"mistral-embed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4b067ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_documentos(documentos, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(documentos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e4d87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_e_armazenar_embeddings(docs, collection_name):\n",
    "    store = Chroma.from_documents(\n",
    "        docs,\n",
    "        embedding=get_embeddings(),\n",
    "        collection_name=collection_name\n",
    "    )\n",
    "    return store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c32b8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurar_llm(modelo):\n",
    "    match modelo:\n",
    "        case \"gemini\":\n",
    "            return ChatGoogleGenerativeAI(model=\"gemini-2.5-pro-preview-03-25\")\n",
    "        case \"groq\":\n",
    "            return ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b310af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consultar_groq(vectorstore, query):\n",
    "    # Recupera os chunks mais relevantes\n",
    "    docs = vectorstore.similarity_search(query, k=3)\n",
    "    contexto = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Consulta LLM via Groq\n",
    "    llm = configurar_llm(\"groq\")\n",
    "    prompt = f\"Responda a pergunta usando apenas as informações abaixo:\\n\\n{contexto}\\n\\nPergunta: {query}\"\n",
    "    resposta = llm.invoke(prompt)\n",
    "    return resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32f901c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1202, which is longer than the specified 1000\n",
      "Created a chunk of size 1019, which is longer than the specified 1000\n",
      "Created a chunk of size 1577, which is longer than the specified 1000\n",
      "Created a chunk of size 1068, which is longer than the specified 1000\n",
      "Created a chunk of size 1080, which is longer than the specified 1000\n",
      "Created a chunk of size 1106, which is longer than the specified 1000\n",
      "Created a chunk of size 1035, which is longer than the specified 1000\n",
      "Created a chunk of size 1039, which is longer than the specified 1000\n",
      "Created a chunk of size 1309, which is longer than the specified 1000\n",
      "Created a chunk of size 1514, which is longer than the specified 1000\n",
      "Created a chunk of size 1713, which is longer than the specified 1000\n",
      "Created a chunk of size 1597, which is longer than the specified 1000\n",
      "Created a chunk of size 1154, which is longer than the specified 1000\n",
      "Created a chunk of size 1958, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta da LLM: content='De acordo com o texto fornecido, os objetivos específicos do estudo de boas práticas de gestão do conhecimento em startups não são explicitamente listados. No entanto, podemos inferir que os objetivos incluem:\\n\\n1. **Identificar desafios**: Entender como a rotina acelerada e a alta rotatividade de funcionários impactam a gestão do conhecimento em startups.\\n2. **Compreender a importância da gestão do conhecimento**: Reconhecer a gestão do conhecimento como um dos pilares fundamentais para o sucesso das startups, juntamente com a organização ágil e as capacidades dinâmicas.\\n3. **Descobrir práticas eficazes**: Explorar iniciativas bem-sucedidas ou ideias que melhoram a gestão de conhecimento em startups, como a colaboração e o compartilhamento de conhecimento entre os times.\\n4. **Entender a relação com a inovação**: Compreender como a gestão do conhecimento em startups está alinhada com os princípios da inovação aberta e como pode ser um diferencial competitivo.\\n5. **Coletar recomendações**: Obter sugestões de melhorias e recomendações de profissionais experientes em startups para melhorar a gestão do conhecimento.\\n\\nEsses objetivos podem ser inferidos a partir das perguntas apresentadas no texto, que visam explorar as práticas de gestão do conhecimento em startups e coletar informações para melhorar a gestão do conhecimento nesse tipo de empresa.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 342, 'prompt_tokens': 852, 'total_tokens': 1194, 'completion_time': 1.2436363639999999, 'prompt_time': 0.056150222, 'queue_time': 0.278112499, 'total_time': 1.299786586}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None} id='run--fa5a5636-20e8-435a-b86a-d9fd62ccbfe0-0' usage_metadata={'input_tokens': 852, 'output_tokens': 342, 'total_tokens': 1194}\n"
     ]
    }
   ],
   "source": [
    "docs = carregar_documentos(folder)\n",
    "chunks = dividir_documentos(docs, chunk_size=1000, chunk_overlap=200)\n",
    "store = criar_e_armazenar_embeddings(chunks, collection_name=\"km-db\")\n",
    "\n",
    "# 2. Consultar usando Groq (substitua pela sua API Key real!)\n",
    "pergunta = \"Quais são os objetivos especificos do estudo de boas praticas de gestão do conhecimento em startups?\"\n",
    "resposta = consultar_groq(store, pergunta)\n",
    "print(\"Resposta da LLM:\", resposta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-knowledge-managment-oo58KjW1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
